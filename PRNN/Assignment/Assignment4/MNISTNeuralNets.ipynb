{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========= ASSIGNING 1 GPU FOR RUNNING THE CODE =========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3740133105350157692\n",
      ", name: \"/gpu:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 8115050906\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 9012146490309624114\n",
      "physical_device_desc: \"device: 0, name: Graphics Device, pci bus id: 0000:4b:00.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==================== READ DATA ===================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readFeatures(fileName):\n",
    "    f = open(fileName, \"r+\")\n",
    "    features = []\n",
    "\n",
    "    for line in f.readlines():\n",
    "        feat = line.split(\",\")\n",
    "        feat = map(float, feat)\n",
    "        features.append(feat)\n",
    "    features = np.asarray(features)\n",
    "    f.close()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readLabels(fileName, onehot = True):\n",
    "    f = open(fileName, \"r+\")\n",
    "    labels = []\n",
    "    for line in f.readlines():\n",
    "        if onehot == True:\n",
    "            label = np.zeros(10)\n",
    "            label[(int)(line)] = 1\n",
    "        else:\n",
    "            label = (int)(line)\n",
    "        labels.append(label)    \n",
    "    labels = np.asarray(labels)\n",
    "    f.close()\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainFileNameFeatures = \"train_set/train_set_images.txt\"\n",
    "trainFileNameLabels = \"train_set/train_set_labels.txt\"\n",
    "trainFeatures = readFeatures(trainFileNameFeatures)\n",
    "trainLabels = readLabels(trainFileNameLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validFileNameFeatures = \"validation-test/validation_set_images.txt\"\n",
    "validFileNameLabels = \"validation-test/validation_set_labels.txt\"\n",
    "validFeatures = readFeatures(validFileNameFeatures)\n",
    "validLabels = readLabels(validFileNameLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testFileNameFeatures = \"validation-test/test_set_images.txt\"\n",
    "testFileNameLabels = \"validation-test/test_set_labels.txt\"\n",
    "testFeatures = readFeatures(testFileNameFeatures)\n",
    "testLabels = readLabels(testFileNameLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ================== NEURAL NETWORK =================== "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hidden Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputLayer = 784\n",
    "hiddenLayer1 = 500\n",
    "outputLayer = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weightsOneLayer = {\n",
    "    'W1' : tf.Variable(tf.zeros([inputLayer, hiddenLayer1])),\n",
    "    'W2' : tf.Variable(tf.zeros([hiddenLayer1, outputLayer]))\n",
    "}\n",
    "biasOneLayer = {\n",
    "    'b1' : tf.Variable(tf.zeros([hiddenLayer1])),\n",
    "    'b2' : tf.Variable(tf.zeros([outputLayer]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def oneHiddenLayerModel(x, weights, bias):\n",
    "    layer1Input = x\n",
    "    layer1Output = x\n",
    "    \n",
    "    layer2Input = tf.add(tf.matmul(layer1Output, weights['W1']), bias['b1'])\n",
    "    layer2Output = tf.nn.sigmoid(layer2Input)\n",
    "    \n",
    "    layer3Input = tf.add(tf.matmul(layer2Output, weights['W2']), bias['b2'])\n",
    "    layer3Output = tf.nn.sigmoid(layer3Input)\n",
    "    \n",
    "    y = tf.nn.softmax(layer3Output)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputLayer = 784\n",
    "hiddenLayer1 = 500\n",
    "hiddenLayer2 = 200\n",
    "outputLayer = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weightsTwoLayer = {\n",
    "    'W1' : tf.Variable(tf.zeros([inputLayer, hiddenLayer1])),\n",
    "    'W2' : tf.Variable(tf.zeros([hiddenLayer1, hiddenLayer2])),\n",
    "    'W3' : tf.Variable(tf.zeros([hiddenLayer2, outputLayer]))\n",
    "}\n",
    "biasTwoLayer = {\n",
    "    'b1' : tf.Variable(tf.zeros([hiddenLayer1])),\n",
    "    'b2' : tf.Variable(tf.zeros([hiddenLayer2])),\n",
    "    'b3' : tf.Variable(tf.zeros([outputLayer]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def twoHiddenLayerModel(x, weights, bias):\n",
    "    layer1Input = x\n",
    "    layer1Output = x\n",
    "    \n",
    "    layer2Input = tf.add(tf.matmul(layer1Output, weights['W1']), bias['b1'])\n",
    "    layer2Output = tf.nn.sigmoid(layer2Input)\n",
    "    \n",
    "    layer3Input = tf.add(tf.matmul(layer2Output, weights['W2']), bias['b2'])\n",
    "    layer3Output = tf.nn.sigmoid(layer3Input)\n",
    "    \n",
    "    layer4Input = tf.add(tf.matmul(layer3Output, weights['W3']), bias['b3'])\n",
    "    layer4Output = tf.nn.sigmoid(layer4Input)\n",
    "    \n",
    "    y = tf.nn.softmax(layer4Output)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Five Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputLayer = 784\n",
    "hiddenLayer1 = 500\n",
    "hiddenLayer2 = 600\n",
    "hiddenLayer3 = 250\n",
    "hiddenLayer4 = 110\n",
    "hiddenLayer5 = 40\n",
    "outputLayer = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weightsFiveLayer = {\n",
    "    'W1' : tf.Variable(tf.zeros([inputLayer, hiddenLayer1])),\n",
    "    'W2' : tf.Variable(tf.zeros([hiddenLayer1, hiddenLayer2])),\n",
    "    'W3' : tf.Variable(tf.zeros([hiddenLayer2, hiddenLayer3])),\n",
    "    'W4' : tf.Variable(tf.zeros([hiddenLayer3, hiddenLayer4])),\n",
    "    'W5' : tf.Variable(tf.zeros([hiddenLayer4, hiddenLayer5])),\n",
    "    'W6' : tf.Variable(tf.zeros([hiddenLayer5, outputLayer]))\n",
    "}\n",
    "biasFiveLayer = {\n",
    "    'b1' : tf.Variable(tf.zeros([hiddenLayer1])),\n",
    "    'b2' : tf.Variable(tf.zeros([hiddenLayer2])),\n",
    "    'b3' : tf.Variable(tf.zeros([hiddenLayer3])),\n",
    "    'b4' : tf.Variable(tf.zeros([hiddenLayer4])),\n",
    "    'b5' : tf.Variable(tf.zeros([hiddenLayer5])),\n",
    "    'b6' : tf.Variable(tf.zeros([outputLayer]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fiveHiddenLayerModel(x, weights, bias):\n",
    "    layer1Input = x\n",
    "    layer1Output = x\n",
    "    \n",
    "    layer2Input = tf.add(tf.matmul(layer1Output, weights['W1']), bias['b1'])\n",
    "    layer2Output = tf.nn.sigmoid(layer2Input)\n",
    "    \n",
    "    layer3Input = tf.add(tf.matmul(layer2Output, weights['W2']), bias['b2'])\n",
    "    layer3Output = tf.nn.sigmoid(layer3Input)\n",
    "    \n",
    "    layer4Input = tf.add(tf.matmul(layer3Output, weights['W3']), bias['b3'])\n",
    "    layer4Output = tf.nn.sigmoid(layer4Input)\n",
    "    \n",
    "    layer5Input = tf.add(tf.matmul(layer4Output, weights['W4']), bias['b4'])\n",
    "    layer5Output = tf.nn.sigmoid(layer5Input)\n",
    "    \n",
    "    layer6Input = tf.add(tf.matmul(layer5Output, weights['W5']), bias['b5'])\n",
    "    layer6Output = tf.nn.sigmoid(layer6Input)\n",
    "    \n",
    "    layer7Input = tf.add(tf.matmul(layer6Output, weights['W6']), bias['b6'])\n",
    "    layer7Output = tf.nn.sigmoid(layer7Input)\n",
    "    \n",
    "    y = tf.nn.softmax(layer7Output)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Neural Network Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "    d = tf.placeholder(tf.float32, [None, 10])\n",
    "    y = fiveHiddenLayerModel(x, weightsFiveLayer, biasFiveLayer)\n",
    "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(d * tf.log(y), reduction_indices=[1]))\n",
    "    train_step = tf.train.AdamOptimizer().minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "bSize = 100\n",
    "with sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for _ in range(100):\n",
    "        for i in range(0, trainLabels.shape[0], bSize):\n",
    "            sess.run(train_step, feed_dict = {x: trainFeatures[i:i+bSize], d: trainLabels[i:i+bSize]})\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(d,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print(sess.run(accuracy, feed_dict={x: testFeatures, d: testLabels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =========== CONVOLUTIONAL NEURAL NETWORK ============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight - bias helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weightCNN(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def biasCNN(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and max pool helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight referencing and initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WConv1 = weightCNN([5, 5, 1, 32])\n",
    "bConv1 = biasCNN([32])\n",
    "\n",
    "WConv2 = weightCNN([5, 5, 32, 64])\n",
    "bConv2 = biasCNN([64])\n",
    "\n",
    "weightsConv = {\n",
    "    'W1' : WConv1,\n",
    "    'W2' : WConv2\n",
    "}\n",
    "\n",
    "biasConv = {\n",
    "    'b1' : bConv1,\n",
    "    'b2' : bConv2\n",
    "}\n",
    "\n",
    "weightFC = {\n",
    "    'W1' : weightCNN([7*7*64, 1024]),\n",
    "    'W2' : weightCNN([1024, 10])\n",
    "}\n",
    "\n",
    "biasFC = {\n",
    "    'b1' : biasCNN([1024]),\n",
    "    'b2' : biasCNN([10])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural network 2 conv layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = False\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convolutionalNet(x, weightsConv, biasConv, weightFC, biasFC):\n",
    "    layer1Input = x\n",
    "    layer1Output = x\n",
    "    \n",
    "    conv1Input = tf.add(conv2d(layer1Input, weightsConv['W1']), biasConv['b1'])\n",
    "    conv1Output = tf.nn.relu(conv1Input)\n",
    "    \n",
    "    maxPool1Input = conv1Output\n",
    "    maxPool1Output = max_pool_2x2(maxPool1Input)\n",
    "    \n",
    "    conv2Input = tf.add(conv2d(maxPool1Output, weightsConv['W2']), biasConv['b2'])\n",
    "    conv2Output = tf.nn.relu(conv2Input)\n",
    "    \n",
    "    maxPool2Input = conv2Output\n",
    "    self.maxPool2Output =maxPool2Input\n",
    "    \n",
    "    print(maxPool2Output)\n",
    "    \n",
    "    \n",
    "    fc1Input = tf.reshape(maxPool2Output, [-1, 7*7*64])\n",
    "    fc1Output = fc1Input\n",
    "    \n",
    "    fc2Input = tf.nn.relu(tf.add(tf.matmul(fc1Output, weightFC['W1']), biasFC['b1']))\n",
    "    fc2Drop = tf.nn.dropout(fc2Input, keep_prob)\n",
    "    \n",
    "    fc3Input = tf.add(tf.matmul(fc2Drop, weightFC['W2']), biasFC['b2'])\n",
    "    fc3Output = tf.nn.softmax(fc3Input)\n",
    "    \n",
    "    return fc3Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32, device=/device:GPU:0)\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "    d = tf.placeholder(tf.float32, [None, 10])\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    x_image = tf.reshape(x , [-1,28,28,1])\n",
    "    y_conv = convolutionalNet(x_image, weightsConv, biasConv, weightFC, biasFC)\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = d, logits = y_conv))\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print \"Process started\"\n",
    "sess = tf.Session(config=config)\n",
    "bSize = 500\n",
    "with sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for i in range(2000):\n",
    "        for j in range(0, trainFeatures.shape[0], bSize):\n",
    "            train_step.run(feed_dict={x : trainFeatures[j:j+bSize], d : trainLabels[j:j+bSize], keep_prob : 0.5})\n",
    "        if(i%50==0):\n",
    "            print \"Iteration \" + str(i) + \" took \" + str(time.time()-start_time)\n",
    "            start_time = time.time()\n",
    "            \n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(d, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print \"Total time taken : \" + str(time.time() - start_time)\n",
    "    print \"Test accuracy : \" + str(accuracy.eval(feed_dict={x : testFeatures, d: testLabels, keep_prob : 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.reshape(trainFeatures[0:100], [-1,28,28,1]).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
