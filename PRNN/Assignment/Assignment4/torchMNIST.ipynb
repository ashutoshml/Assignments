{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from __future__ import print_function\n",
    "from torch import np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readFeatures(fileName, istorch = True):\n",
    "    f = open(fileName, \"r+\")\n",
    "    features = []\n",
    "\n",
    "    for line in f.readlines():\n",
    "        feat = line.split(\",\")\n",
    "        feat = map(float, feat)\n",
    "        features.append(feat)\n",
    "    features = np.asarray(features)\n",
    "    if istorch:\n",
    "        features = torch.from_numpy(features)\n",
    "        features = features.float()\n",
    "    f.close()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readLabels(fileName, onehot = False, istorch = True):\n",
    "    f = open(fileName, \"r+\")\n",
    "    labels = []\n",
    "    for line in f.readlines():\n",
    "        if onehot == True:\n",
    "            label = np.zeros(10)\n",
    "            label[(int)(line)] = 1\n",
    "        else:\n",
    "            label = (int)(line)\n",
    "        labels.append(label)    \n",
    "    labels = np.asarray(labels)\n",
    "    if istorch:\n",
    "        labels = torch.from_numpy(labels)\n",
    "    f.close()\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainFileNameFeatures = \"train_set/train_set_images.txt\"\n",
    "trainFileNameLabels = \"train_set/train_set_labels.txt\"\n",
    "trainFeatures = readFeatures(trainFileNameFeatures)\n",
    "trainLabels = readLabels(trainFileNameLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validFileNameFeatures = \"validation-test/validation_set_images.txt\"\n",
    "validFileNameLabels = \"validation-test/validation_set_labels.txt\"\n",
    "validFeatures = readFeatures(validFileNameFeatures)\n",
    "validLabels = readLabels(validFileNameLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 784])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validFeatures.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testFileNameFeatures = \"validation-test/test_set_images.txt\"\n",
    "testFileNameLabels = \"validation-test/test_set_labels.txt\"\n",
    "testFeatures = readFeatures(testFileNameFeatures)\n",
    "testLabels = readLabels(testFileNameLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3L"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.set_device(3)\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet (\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (fc1): Linear (3136 -> 1024)\n",
      "  (fc2): Linear (1024 -> 10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5, padding=(2,2))\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, padding= (2,2))\n",
    "        self.fc1 = nn.Linear(7*7*64, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "convnet = ConvNet()\n",
    "convnet.cuda()\n",
    "print(convnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterionConvNet = nn.CrossEntropyLoss()\n",
    "optimizerConvNet = optim.Adam(convnet.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b_size = 500\n",
    "start_time = time.time()\n",
    "for j in range(0, 100):\n",
    "    running_loss = 0.0\n",
    "    for i in range(0, int(trainFeatures.size()[0]), b_size):\n",
    "        inputs = trainFeatures[i:i+b_size]\n",
    "        inputs = inputs.view(-1,1,28,28)\n",
    "        inputs = Variable(inputs.cuda())\n",
    "        outputs = convnet(inputs)\n",
    "        \n",
    "        targets = Variable(trainLabels[i:i+b_size].cuda())\n",
    "        optimizerConvNet.zero_grad()\n",
    "        \n",
    "        loss = criterionConvNet(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizerConvNet.step()\n",
    "        \n",
    "        running_loss += loss.data[0]\n",
    "            \n",
    "    if j%50==49:\n",
    "        print(\"Iteration : \" + str(j) + \" took : \" + str(time.time()-start_time))\n",
    "        print('[%d, %5d] loss: %.15f' % (j+1, i+1, running_loss / 2000))\n",
    "        running_loss = 0.0\n",
    "        start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional neural network test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for i in range(0, len(testFeatures)):\n",
    "    images, labels = testFeatures[i], testLabels[i]\n",
    "    outputs = convnet(Variable(images).view(-1,1,28,28).cuda())\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += 1\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: ' + str(100.0 * correct / total*1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed Forward Single hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class OneLayerNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OneLayerNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "oneNet = OneLayerNet()\n",
    "oneNet.cuda()\n",
    "print(oneNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "criteriononenet = nn.CrossEntropyLoss()\n",
    "optimizeronenet = optim.Adam(oneNet.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b_size = 1000\n",
    "start_time = time.time()\n",
    "for i in range(0,100):\n",
    "    for j in range(0, len(trainFeatures), b_size):\n",
    "        inputs = trainFeatures[j:j+b_size]\n",
    "        inputs = Variable(inputs).cuda()\n",
    "        labels = Variable(trainLabels[j:j+b_size]).cuda()\n",
    "        optimizeronenet.zero_grad()\n",
    "        outputs = oneNet(inputs)\n",
    "        loss = criteriononenet(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizeronenet.step()\n",
    "\n",
    "    if i%10==0:\n",
    "        print(\"Iteration : \" + str(j) + \" took : \" + str(time.time()-start_time))\n",
    "        start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for i in range(0, len(testFeatures)):\n",
    "    images, labels = testFeatures[i].view(-1,784), testLabels[i]\n",
    "    outputs = oneNet(Variable(images).cuda())\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += 1\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: ' + str(100.0 * correct / total*1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed Forward Two Hidden Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TwoLayerNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 500)\n",
    "        self.fc2 = nn.Linear(500,250)\n",
    "        self.fc3 = nn.Linear(250, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "twoNet = TwoLayerNet()\n",
    "twoNet.cuda()\n",
    "print(twoNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "criterionTwoLayer = nn.CrossEntropyLoss()\n",
    "optimizerTwoLayer = optim.Adam(twoNet.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b_size = 1000\n",
    "start_time = time.time()\n",
    "for i in range(0,100):\n",
    "    for j in range(0, len(trainFeatures), b_size):\n",
    "        inputs = trainFeatures[j:j+b_size]\n",
    "        inputs = Variable(inputs).cuda()\n",
    "        labels = Variable(trainLabels[j:j+b_size]).cuda()\n",
    "        \n",
    "        optimizerTwoLayer.zero_grad()\n",
    "        outputs = twoNet(inputs)\n",
    "        loss = criterionTwoLayer(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizerTwoLayer.step()\n",
    "\n",
    "    if i%10==0:\n",
    "        print(\"Iteration : \" + str(j) + \" took : \" + str(time.time()-start_time))\n",
    "        start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for i in range(0, len(testFeatures)):\n",
    "    images, labels = testFeatures[i].view(-1,784), testLabels[i]\n",
    "    outputs = twoNet(Variable(images).cuda())\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += 1\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: ' + str(100.0 * correct / total*1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed Forward 5 Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class FiveLayerNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FiveLayerNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 500)\n",
    "        self.fc2 = nn.Linear(500, 250)\n",
    "        self.fc3 = nn.Linear(250, 200)\n",
    "        self.fc4 = nn.Linear(200, 300)\n",
    "        self.fc5 = nn.Linear(300, 150)\n",
    "        self.fc6 = nn.Linear(150, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.sigmoid(self.fc4(x))\n",
    "        x = F.sigmoid(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        return x\n",
    "\n",
    "fiveNet = FiveLayerNet()\n",
    "fiveNet.cuda()\n",
    "print(fiveNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "criterionFiveLayer = nn.CrossEntropyLoss()\n",
    "optimizerFiveLayer = optim.Adam(fiveNet.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b_size = 1000\n",
    "start_time = time.time()\n",
    "for i in range(0,100):\n",
    "    for j in range(0, len(trainFeatures), b_size):\n",
    "        inputs = trainFeatures[j:j+b_size]\n",
    "        inputs = Variable(inputs).cuda()\n",
    "        labels = Variable(trainLabels[j:j+b_size]).cuda()\n",
    "        \n",
    "        optimizerFiveLayer.zero_grad()\n",
    "        outputs = fiveNet(inputs)\n",
    "        loss = criterionFiveLayer(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizerFiveLayer.step()\n",
    "\n",
    "    if i%10==0:\n",
    "        print(\"Iteration : \" + str(j) + \" took : \" + str(time.time()-start_time))\n",
    "        start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for i in range(0, len(testFeatures)):\n",
    "    images, labels = testFeatures[i].view(-1,784), testLabels[i]\n",
    "    outputs = fiveNet(Variable(images).cuda())\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += 1\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: ' + str(100.0 * correct / total*1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainFileNameFeatures = \"train_set/train_set_images.txt\"\n",
    "trainFileNameLabels = \"train_set/train_set_labels.txt\"\n",
    "trainFeatures = readFeatures(trainFileNameFeatures, istorch=False)\n",
    "trainLabels = readLabels(trainFileNameLabels, onehot = False, istorch = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validFileNameFeatures = \"validation-test/validation_set_images.txt\"\n",
    "validFileNameLabels = \"validation-test/validation_set_labels.txt\"\n",
    "validFeatures = readFeatures(validFileNameFeatures, istorch = False)\n",
    "validLabels = readLabels(validFileNameLabels, onehot = False, istorch = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testFileNameFeatures = \"validation-test/test_set_images.txt\"\n",
    "testFileNameLabels = \"validation-test/test_set_labels.txt\"\n",
    "testFeatures = readFeatures(testFileNameFeatures, istorch = False)\n",
    "testLabels = readLabels(testFileNameLabels, onehot = False, istorch = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SVMClassifier = SVC(C=1e3, tol=1e-5, kernel='rbf')\n",
    "SVMClassifier.fit(trainFeatures, trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SVMClassifier.score(testFeatures, testLabels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
